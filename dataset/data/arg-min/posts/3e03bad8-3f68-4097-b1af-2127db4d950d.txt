<article class="post-content">
<p>Last November was a dramatic wake-up call to many of us in information technology, and I’ve spent a large part of the last year learning about how I and others in similar positions can help to fix the mess that tech has enabled.</p>
<p>Those of you who know me in real life know I’m an impatient person. But fixing everything wrong with our information infrastructures is a long game, and it’s going to take persistence and patience to see it through. I’m all in and know it’s a long term commitment.</p>
<p>Below are a few thoughts on what we can all do as individuals based on what I’ve learned this past year.  These thoughts are based on conversations with many great people, and I’d particularly like to thank <a href="https://people.eecs.berkeley.edu/~odemasi/">Orianna DeMasi</a>, <a href="http://mrtz.org">Moritz Hardt</a>, <a href="http://arthistory.berkeley.edu/person/1799032-lauren-kroiz">Lauren Kroiz</a>, and <a href="http://www.columbia.edu/~chw2/">Chris Wiggins</a> for reading drafts of this post and offering invaluable suggestions. They’ve all had tremendous influence on my thinking about these issues.</p>
<h2 id="ethics-is-unavoidable-in-data-science">Ethics is unavoidable in data science</h2>
<p>When a technology increases its capability to impact humans, it’s a moral issue. Ethics is now an unavoidable part of information technology, and should be covered in depth in <em>any course</em> on the subject. It should not be relegated to a one-off ethics course for undergrads to blow off.</p>
<p>I had taken IRB training as a post-doc when I was involved in human subjects research, but I refreshed my familiarity this year, and it was shocking how many of the issues are so relevant to computing and yet ignored by many oblivious computer scientists.</p>
<p>I’d encourage everyone out there with an “edu” address to take their university’s training on ethical research with human subjects. If you don’t have an “edu” address, read Chapter 6 in Matt Salganik’s great new book “<a href="http://www.bitbybitbook.com/en/ethics/">Bit by Bit</a>.”  There are a standard set of principles drawn from reflections on mistakes and ethical lapses by scientists and statisticians during and after the second world war.  The ideas are straightforward but easy to overlook when pressured by a deadline: All interactions must minimize risk to people and must have some possibility of human benefit. All researchers must respect the law rather than try to subvert it.  All research must promote justice. How often do coders at social media companies think about these issues before shipping some new piece of code?</p>
<p>On a positive note, it was amazing for me to see the <a href="https://www.wired.com/story/artificial-intelligence-seeks-an-ethical-conscience">number of speakers at NIPS addressing ethical issues</a>.  That’s incredible positive progress, and we all can do more to bring attention to these issues. Follow the work of the researchers out there who have been committed for years.  Scholars like <a href="http://technosociology.org/">Zeynep Tufecki</a>, <a href="http://www.katecrawford.net/">Kate Crawford</a>, and <a href="https://mathbabe.org/">Cathy O’Neil</a> have been sounding these calls loudly for a long time. Read their work and share it with your colleagues and students.</p>
<h2 id="take-responsibility">Take responsibility</h2>
<p>Some of the most important things we can do as technologists is decide what projects we will and will not work on.  For example, if you are using machine learning to advance the persuasion architectures towards a fractured and misinformed-by-design electorate, you are making a moral decision.</p>
<p>Mike Monteiro asked designers to “find your ethical strength, and bring it to your day job with you every day” in a <a href="https://deardesignstudent.com/ethics-cant-be-a-side-hustle-b9e78c090aee">great medium post</a> earlier this year.  Monteiro’s advice applies to data science: the biggest changes can just start with what you do every day. If your job is working on creepy things, or things that don’t align with your own values, ask yourself why! Consider asking your boss to transfer you to a different project. If you like your boss, consider asking your boss if that project is right for the company. Or, more radically, consider if it is possible for you to leave. In 2017 there are abundant opportunities for people who know how to make sense of the world through data. Perhaps you can find the company whose values most align with your own. If you are working in some aspect of data science, you may have more power than you realize to be selective about where you work. Be active, even though it could be scary.</p>
<p>Is it ok to work at Facebook if you are concerned about the negative consequences of the engagement economy? It’s complicated. But so is taking military funding as an academic, and this is something that most of my academic colleagues and I have had to consider. The important thing is owning up to the consequences of  what you’re doing, and deciding whether what you are working on can lead to the moral ends you’d like it to. I know many people who have moved between tech companies to get a raise or a promotion. Those same people should consider whether they could switch jobs to make positive change.</p>
<h2 id="join-forces-and-organize">Join Forces and Organize</h2>
<p>I’ve met great people working on great digital activism. In particular, <a href="http://datafordemocracy.org/">data for democracy</a> is working hard on issues you care about and are always looking for volunteers. I’ve also met many wonderful academics working on applying their knowledge of data science for social good. These people are out there, and the more we make connections to each other, the louder our unified voice can be.</p>
<p>Know that organization does not necessarily mean becoming an activist. It also means finding like-minded people who can collaborate with you towards better ends. I’m fortunate to be a professor because I am constantly pulled by young people who are smarter than me and who have better ideas on how to change things. My students have shaped my views on actionable items for positive change more than anyone else, and I’m deeply grateful to all of them.</p>
<h2 id="donate">Donate</h2>
<p>Finally, let me just state the obvious. Tech is booming, and I know many of you are making a lot of money. I know that it’s expensive to live in Silicon Valley, but that money can really help out, and I think in these trying times, we all have to sacrifice a bit to ensure that causes we care about continue.</p>
<p>Maciej Cegłowski had a <a href="https://twitter.com/Pinboard/status/942759494479765504">provocative formula</a> for calculating how much to donate: “value of your stock shares today - value of your shares on Nov 8, 2016 = your contribution budget.” The tech sector continues to make out like bandits, but we don’t do enough to ensure that everyone else benefits as well.  This is easy to change: find an underfunded candidate to support. Find a list of charities where you can donate. We can also volunteer our time: this could take the form of donating tech skills or could simply be traditional methods of writing post cards and knocking on doors. But the bottom line is that your time and effort count, and they matter, and every little bit makes a difference. I’m personally coming out of 2017 far more optimistic about the future than I was going in. I think if we all reflect on how we can make a difference, 2018 can be even better.</p>
</article>